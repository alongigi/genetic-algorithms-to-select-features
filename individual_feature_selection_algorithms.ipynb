{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyPM9J21Q4mXJzk9t5V/hJrX"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Askn1naxHZmU",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737710235305,
     "user_tz": -120,
     "elapsed": 3673,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "outputId": "3919f3e4-2ad3-4959-bbe6-1bca9704beeb",
    "ExecuteTime": {
     "end_time": "2025-01-24T20:12:55.592375Z",
     "start_time": "2025-01-24T20:12:53.950232Z"
    }
   },
   "source": "!pip install ucimlrepo",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from ucimlrepo) (2024.12.14)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest"
   ],
   "metadata": {
    "id": "CeNLwRfGHPGj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737710235305,
     "user_tz": -120,
     "elapsed": 3,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-01-24T20:13:18.359301Z",
     "start_time": "2025-01-24T20:13:17.257236Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ISOLET_DB_INDEX: int = 54\n",
    "SPAMBASE_DB_INDEX: int = 94"
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-24T20:13:20.639121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read first dataset\n",
    "isolet = fetch_ucirepo(id=ISOLET_DB_INDEX)\n",
    "\n",
    "features = isolet.data.features\n",
    "target_variables = isolet.data.targets\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.573251Z",
     "start_time": "2025-01-24T20:11:05.567841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Print missing values and maximum and minimum values in the features of the first dataset\n",
    "X_df = pd.DataFrame(features)\n",
    "y_df = pd.DataFrame(target_variables)\n",
    "\n",
    "print(\"Missing values in X:\", X_df.isnull().sum().sum())\n",
    "print(\"Missing values in y:\", y_df.isnull().sum().sum())\n",
    "\n",
    "print(\"Minimum value across all features:\", X_df.min().min())\n",
    "print(\"Maximum value across all features:\", X_df.max().max())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X: 0\n",
      "Missing values in y: 0\n",
      "Minimum value across all features: -1.0\n",
      "Maximum value across all features: 1.0\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "# Normalize the first dataset\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_df)\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X_df.columns)\n",
    "\n",
    "print(X_scaled_df.min().min())\n",
    "print(X_scaled_df.max().max())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZ5rMZL_e4Pa",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737710237868,
     "user_tz": -120,
     "elapsed": 6,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "outputId": "3aba8309-e5c9-4a8c-efed-8c9a223258ae",
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.610241Z",
     "start_time": "2025-01-24T20:11:05.603872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.681573Z",
     "start_time": "2025-01-24T20:11:05.678284Z"
    }
   },
   "cell_type": "code",
   "source": "RANDOM_FOREST_SEED: int = 42",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# # Read second dataset\n",
    "# spambase = fetch_ucirepo(id=94)\n",
    "\n",
    "# X = spambase.data.features\n",
    "# y = spambase.data.targets"
   ],
   "metadata": {
    "id": "Y3632T4akePZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737710237868,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.732875Z",
     "start_time": "2025-01-24T20:11:05.729839Z"
    }
   },
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# # Print missing values and maximum and minimum values in the features of the second dataset\n",
    "\n",
    "# X_df = pd.DataFrame(X)\n",
    "# y_df = pd.DataFrame(y)\n",
    "\n",
    "# print(\"Missing values in X:\", X_df.isnull().sum().sum())\n",
    "# print(\"Missing values in y:\", y_df.isnull().sum().sum())\n",
    "\n",
    "\n",
    "# print(\"Minimum value across all features:\", X_df.min().min())\n",
    "# print(\"Maximum value across all features:\", X_df.max().max())"
   ],
   "metadata": {
    "id": "rEtLDi40khHC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737710237868,
     "user_tz": -120,
     "elapsed": 5,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.740631Z",
     "start_time": "2025-01-24T20:11:05.737865Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.810557Z",
     "start_time": "2025-01-24T20:11:05.807806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # Normalize the second dataset\n",
    "# scaler = MinMaxScaler()\n",
    "# X_scaled = scaler.fit_transform(X_df)\n",
    "\n",
    "# X_scaled_df = pd.DataFrame(X_scaled, columns=X_df.columns)\n",
    "\n",
    "# print(X_scaled_df.min().min())\n",
    "# print(X_scaled_df.max().max())\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.818761Z",
     "start_time": "2025-01-24T20:11:05.816572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_after_scaling = X_scaled_df\n",
    "target_variables = y_df.values.ravel()\n"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "def get_top_k_features(selector, feature_names: list, top_features_to_select: int, algorithm: str, verbose: bool = False):\n",
    "  \"\"\"\n",
    "  Get the top k features based on their scores from a SelectKBest selector.\n",
    "\n",
    "  Parameters:\n",
    "  selector (SelectKBest): Fitted SelectKBest object.\n",
    "  feature_names (list): List of feature names (columns of X).\n",
    "  k (int): Number of top features to select.\n",
    "  algorithm (str): The name of the feature selection algorithm.\n",
    "\n",
    "  Returns:\n",
    "  list: Names of the top k features.\n",
    "  \"\"\"\n",
    "  # Retrieve feature scores\n",
    "  scores = selector.scores_\n",
    "\n",
    "  # Create a DataFrame for ranked features\n",
    "  feature_ranking = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Score': scores\n",
    "  }).sort_values(by='Score', ascending=False)\n",
    "  if verbose:\n",
    "    # Display top-ranked features\n",
    "    print(f\"Feature Rankings using {algorithm}:\")\n",
    "    print(feature_ranking)\n",
    "\n",
    "\n",
    "  # Return selected top k features\n",
    "  return feature_ranking.head(top_features_to_select)['Feature'].tolist()"
   ],
   "metadata": {
    "id": "qIJoIpIA_uOj",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737710238141,
     "user_tz": -120,
     "elapsed": 3,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.859264Z",
     "start_time": "2025-01-24T20:11:05.856303Z"
    }
   },
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.899643Z",
     "start_time": "2025-01-24T20:11:05.896678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_fit_random_forest(X_train, X_test, y_train, y_test):\n",
    "  \"\"\"\n",
    "  Builds, trains, and evaluates a Random Forest classification model.\n",
    "\n",
    "  Parameters:\n",
    "  ----------\n",
    "  X_train : pd.DataFrame or np.ndarray\n",
    "      Feature matrix for training the model.\n",
    "  X_test : pd.DataFrame or np.ndarray\n",
    "      Feature matrix for testing the model.\n",
    "  y_train : pd.Series or np.ndarray\n",
    "      Target labels for training the model.\n",
    "  y_test : pd.Series or np.ndarray\n",
    "      True target labels for testing the model.\n",
    "\n",
    "  Returns:\n",
    "  float: The accuracy of the model on the selected features\n",
    "  \"\"\"\n",
    "  # Build a simple classification model\n",
    "  model = RandomForestClassifier(random_state=RANDOM_FOREST_SEED)\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Make predictions\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # Evaluate the model\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  print(\"Model Accuracy:\", accuracy)\n",
    "\n",
    "  # Detailed performance metrics\n",
    "  # print(\"\\nClassification Report:\")\n",
    "  # print(classification_report(y_test, y_pred))\n",
    "\n",
    "  # Return the accuracy of the model\n",
    "  return accuracy\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.940379Z",
     "start_time": "2025-01-24T20:11:05.937093Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_features_with_selector(selector: SelectKBest,\n",
    "                                    num_of_features_to_select: int,\n",
    "                                    data_with_features,\n",
    "                                    target_variables,\n",
    "                                    algorithm: str = \"\",\n",
    "                                    verbose: bool = False\n",
    "                                    ):\n",
    "      \"\"\"\n",
    "      :param selector: SelectKBest object.\n",
    "      :param num_of_features_to_select:\n",
    "      :param data_with_features: The features are selected from this data.\n",
    "      :param target_variables: The variable the feature selection is used on.\n",
    "      :param algorithm: The algorithm used, as a str. Used for debug printouts.\n",
    "      :param verbose: Enable debug printouts.\n",
    "      :return:\n",
    "      \"\"\"\n",
    "      selector.fit(data_with_features, target_variables)\n",
    "\n",
    "      # Rank the features using Chi-Square algorithm\n",
    "      top_features = get_top_k_features(selector=selector, feature_names=features.columns,\n",
    "                                        top_features_to_select=num_of_features_to_select, algorithm=algorithm,\n",
    "                                        verbose=verbose)\n",
    "\n",
    "      return data_with_features[top_features]"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:05.980961Z",
     "start_time": "2025-01-24T20:11:05.978590Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MIN_FEATURES: int = 5\n",
    "MAX_FEATURES: int = 10\n",
    "TRAIN_TEST_SPLIT_RATIO: float = 0.2"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:06.603120Z",
     "start_time": "2025-01-24T20:11:06.018949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Apply Chi-Square\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "results = []\n",
    "for k in range(MIN_FEATURES, MAX_FEATURES):\n",
    "  # SelectKBest with chi2 evaluates all features\n",
    "  X_top = get_top_features_with_selector(\n",
    "      selector=SelectKBest(score_func=chi2, k='all'),\n",
    "      num_of_features_to_select=k,\n",
    "      data_with_features=data_after_scaling,\n",
    "      target_variables=target_variables,\n",
    "      algorithm=\"Chi-Square\",\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "  # Split the data into train and test sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_top, target_variables, test_size=TRAIN_TEST_SPLIT_RATIO, random_state=42)\n",
    "\n",
    "  # Train and fit random forest classification model based on feature selected\n",
    "  print(\"---------------------------------\")\n",
    "  print(f'Amount of features selected: {k}')\n",
    "  accuracy = train_and_fit_random_forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "  results.append((k, accuracy))\n",
    "\n",
    "# Find the best k\n",
    "best_k, best_accuracy = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best k: {best_k}, Best Accuracy: {best_accuracy}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Rankings using Chi-Square:\n",
      "        Feature     Score\n",
      "0    Attribute1  8.238247\n",
      "4    Attribute5  7.879616\n",
      "2    Attribute3  7.118123\n",
      "6    Attribute7  5.559238\n",
      "30  Attribute31  3.662940\n",
      "28  Attribute29  2.632248\n",
      "8    Attribute9  2.587422\n",
      "32  Attribute33  2.416334\n",
      "14  Attribute15  2.382145\n",
      "20  Attribute21  2.347565\n",
      "22  Attribute23  1.955440\n",
      "7    Attribute8  1.826200\n",
      "12  Attribute13  1.596337\n",
      "13  Attribute14  1.521784\n",
      "24  Attribute25  1.485292\n",
      "10  Attribute11  1.061258\n",
      "11  Attribute12  0.948956\n",
      "15  Attribute16  0.759780\n",
      "5    Attribute6  0.740302\n",
      "18  Attribute19  0.696323\n",
      "21  Attribute22  0.631219\n",
      "17  Attribute18  0.617339\n",
      "3    Attribute4  0.517440\n",
      "9   Attribute10  0.504685\n",
      "26  Attribute27  0.373407\n",
      "16  Attribute17  0.366595\n",
      "33  Attribute34  0.155793\n",
      "27  Attribute28  0.104016\n",
      "19  Attribute20  0.061299\n",
      "31  Attribute32  0.060061\n",
      "23  Attribute24  0.001981\n",
      "29  Attribute30  0.000722\n",
      "25  Attribute26  0.000116\n",
      "1    Attribute2       NaN\n",
      "---------------------------------\n",
      "Amount of features selected: 5\n",
      "Model Accuracy: 0.8591549295774648\n",
      "Feature Rankings using Chi-Square:\n",
      "        Feature     Score\n",
      "0    Attribute1  8.238247\n",
      "4    Attribute5  7.879616\n",
      "2    Attribute3  7.118123\n",
      "6    Attribute7  5.559238\n",
      "30  Attribute31  3.662940\n",
      "28  Attribute29  2.632248\n",
      "8    Attribute9  2.587422\n",
      "32  Attribute33  2.416334\n",
      "14  Attribute15  2.382145\n",
      "20  Attribute21  2.347565\n",
      "22  Attribute23  1.955440\n",
      "7    Attribute8  1.826200\n",
      "12  Attribute13  1.596337\n",
      "13  Attribute14  1.521784\n",
      "24  Attribute25  1.485292\n",
      "10  Attribute11  1.061258\n",
      "11  Attribute12  0.948956\n",
      "15  Attribute16  0.759780\n",
      "5    Attribute6  0.740302\n",
      "18  Attribute19  0.696323\n",
      "21  Attribute22  0.631219\n",
      "17  Attribute18  0.617339\n",
      "3    Attribute4  0.517440\n",
      "9   Attribute10  0.504685\n",
      "26  Attribute27  0.373407\n",
      "16  Attribute17  0.366595\n",
      "33  Attribute34  0.155793\n",
      "27  Attribute28  0.104016\n",
      "19  Attribute20  0.061299\n",
      "31  Attribute32  0.060061\n",
      "23  Attribute24  0.001981\n",
      "29  Attribute30  0.000722\n",
      "25  Attribute26  0.000116\n",
      "1    Attribute2       NaN\n",
      "---------------------------------\n",
      "Amount of features selected: 6\n",
      "Model Accuracy: 0.8732394366197183\n",
      "Feature Rankings using Chi-Square:\n",
      "        Feature     Score\n",
      "0    Attribute1  8.238247\n",
      "4    Attribute5  7.879616\n",
      "2    Attribute3  7.118123\n",
      "6    Attribute7  5.559238\n",
      "30  Attribute31  3.662940\n",
      "28  Attribute29  2.632248\n",
      "8    Attribute9  2.587422\n",
      "32  Attribute33  2.416334\n",
      "14  Attribute15  2.382145\n",
      "20  Attribute21  2.347565\n",
      "22  Attribute23  1.955440\n",
      "7    Attribute8  1.826200\n",
      "12  Attribute13  1.596337\n",
      "13  Attribute14  1.521784\n",
      "24  Attribute25  1.485292\n",
      "10  Attribute11  1.061258\n",
      "11  Attribute12  0.948956\n",
      "15  Attribute16  0.759780\n",
      "5    Attribute6  0.740302\n",
      "18  Attribute19  0.696323\n",
      "21  Attribute22  0.631219\n",
      "17  Attribute18  0.617339\n",
      "3    Attribute4  0.517440\n",
      "9   Attribute10  0.504685\n",
      "26  Attribute27  0.373407\n",
      "16  Attribute17  0.366595\n",
      "33  Attribute34  0.155793\n",
      "27  Attribute28  0.104016\n",
      "19  Attribute20  0.061299\n",
      "31  Attribute32  0.060061\n",
      "23  Attribute24  0.001981\n",
      "29  Attribute30  0.000722\n",
      "25  Attribute26  0.000116\n",
      "1    Attribute2       NaN\n",
      "---------------------------------\n",
      "Amount of features selected: 7\n",
      "Model Accuracy: 0.8873239436619719\n",
      "Feature Rankings using Chi-Square:\n",
      "        Feature     Score\n",
      "0    Attribute1  8.238247\n",
      "4    Attribute5  7.879616\n",
      "2    Attribute3  7.118123\n",
      "6    Attribute7  5.559238\n",
      "30  Attribute31  3.662940\n",
      "28  Attribute29  2.632248\n",
      "8    Attribute9  2.587422\n",
      "32  Attribute33  2.416334\n",
      "14  Attribute15  2.382145\n",
      "20  Attribute21  2.347565\n",
      "22  Attribute23  1.955440\n",
      "7    Attribute8  1.826200\n",
      "12  Attribute13  1.596337\n",
      "13  Attribute14  1.521784\n",
      "24  Attribute25  1.485292\n",
      "10  Attribute11  1.061258\n",
      "11  Attribute12  0.948956\n",
      "15  Attribute16  0.759780\n",
      "5    Attribute6  0.740302\n",
      "18  Attribute19  0.696323\n",
      "21  Attribute22  0.631219\n",
      "17  Attribute18  0.617339\n",
      "3    Attribute4  0.517440\n",
      "9   Attribute10  0.504685\n",
      "26  Attribute27  0.373407\n",
      "16  Attribute17  0.366595\n",
      "33  Attribute34  0.155793\n",
      "27  Attribute28  0.104016\n",
      "19  Attribute20  0.061299\n",
      "31  Attribute32  0.060061\n",
      "23  Attribute24  0.001981\n",
      "29  Attribute30  0.000722\n",
      "25  Attribute26  0.000116\n",
      "1    Attribute2       NaN\n",
      "---------------------------------\n",
      "Amount of features selected: 8\n",
      "Model Accuracy: 0.8873239436619719\n",
      "Feature Rankings using Chi-Square:\n",
      "        Feature     Score\n",
      "0    Attribute1  8.238247\n",
      "4    Attribute5  7.879616\n",
      "2    Attribute3  7.118123\n",
      "6    Attribute7  5.559238\n",
      "30  Attribute31  3.662940\n",
      "28  Attribute29  2.632248\n",
      "8    Attribute9  2.587422\n",
      "32  Attribute33  2.416334\n",
      "14  Attribute15  2.382145\n",
      "20  Attribute21  2.347565\n",
      "22  Attribute23  1.955440\n",
      "7    Attribute8  1.826200\n",
      "12  Attribute13  1.596337\n",
      "13  Attribute14  1.521784\n",
      "24  Attribute25  1.485292\n",
      "10  Attribute11  1.061258\n",
      "11  Attribute12  0.948956\n",
      "15  Attribute16  0.759780\n",
      "5    Attribute6  0.740302\n",
      "18  Attribute19  0.696323\n",
      "21  Attribute22  0.631219\n",
      "17  Attribute18  0.617339\n",
      "3    Attribute4  0.517440\n",
      "9   Attribute10  0.504685\n",
      "26  Attribute27  0.373407\n",
      "16  Attribute17  0.366595\n",
      "33  Attribute34  0.155793\n",
      "27  Attribute28  0.104016\n",
      "19  Attribute20  0.061299\n",
      "31  Attribute32  0.060061\n",
      "23  Attribute24  0.001981\n",
      "29  Attribute30  0.000722\n",
      "25  Attribute26  0.000116\n",
      "1    Attribute2       NaN\n",
      "---------------------------------\n",
      "Amount of features selected: 9\n",
      "Model Accuracy: 0.8873239436619719\n",
      "Best k: 7, Best Accuracy: 0.8873239436619719\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": [
    "# Apply Mutual Information Classification (MIC)\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Wrap mutual_info_classif with a fixed random_state\n",
    "mutual_info_classif_with_random_state = lambda X, y: mutual_info_classif(X, y, random_state=42)\n",
    "\n",
    "results = []\n",
    "for k in range(MIN_FEATURES, MAX_FEATURES):\n",
    "  # SelectKBest with mutual_info_classification evaluates all features\n",
    "  X_top = get_top_features_with_selector(\n",
    "      selector=SelectKBest(score_func=mutual_info_classif_with_random_state, k='all'),\n",
    "      num_of_features_to_select=k,\n",
    "      data_with_features=data_after_scaling,\n",
    "      target_variables=target_variables,\n",
    "      algorithm=\"Mutual Information Classification\",\n",
    "      verbose=True\n",
    "  )\n",
    "\n",
    "  # Split the data into train and test sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_top, target_variables, test_size=0.2, random_state=42)\n",
    "\n",
    "  # Train and fit random forest classification model based on feature selected\n",
    "  accuracy = train_and_fit_random_forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "  results.append((k, accuracy))\n",
    "\n",
    "# Find the best k\n",
    "best_k, best_accuracy = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best k: {best_k}, Best Accuracy: {best_accuracy}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUgKQV416YIo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737712620542,
     "user_tz": -120,
     "elapsed": 2191288,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "outputId": "9977bd55-9f64-4c4d-9d92-ad498ebe6e02",
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:07.539078Z",
     "start_time": "2025-01-24T20:11:06.646962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Rankings using Mutual Information Classification:\n",
      "        Feature     Score\n",
      "5    Attribute6  0.297178\n",
      "4    Attribute5  0.292443\n",
      "7    Attribute8  0.286131\n",
      "20  Attribute21  0.279286\n",
      "26  Attribute27  0.276162\n",
      "32  Attribute33  0.259260\n",
      "30  Attribute31  0.249639\n",
      "28  Attribute29  0.248604\n",
      "2    Attribute3  0.245162\n",
      "13  Attribute14  0.243970\n",
      "12  Attribute13  0.241300\n",
      "15  Attribute16  0.238697\n",
      "6    Attribute7  0.232773\n",
      "23  Attribute24  0.221345\n",
      "33  Attribute34  0.220364\n",
      "14  Attribute15  0.217917\n",
      "22  Attribute23  0.215758\n",
      "31  Attribute32  0.207568\n",
      "24  Attribute25  0.204661\n",
      "21  Attribute22  0.201930\n",
      "8    Attribute9  0.200808\n",
      "3    Attribute4  0.196269\n",
      "25  Attribute26  0.193824\n",
      "17  Attribute18  0.189906\n",
      "9   Attribute10  0.189552\n",
      "11  Attribute12  0.185869\n",
      "19  Attribute20  0.185076\n",
      "27  Attribute28  0.183910\n",
      "10  Attribute11  0.172547\n",
      "18  Attribute19  0.160522\n",
      "29  Attribute30  0.154623\n",
      "16  Attribute17  0.152221\n",
      "0    Attribute1  0.097375\n",
      "1    Attribute2  0.000000\n",
      "Model Accuracy: 0.9295774647887324\n",
      "Feature Rankings using Mutual Information Classification:\n",
      "        Feature     Score\n",
      "5    Attribute6  0.297178\n",
      "4    Attribute5  0.292443\n",
      "7    Attribute8  0.286131\n",
      "20  Attribute21  0.279286\n",
      "26  Attribute27  0.276162\n",
      "32  Attribute33  0.259260\n",
      "30  Attribute31  0.249639\n",
      "28  Attribute29  0.248604\n",
      "2    Attribute3  0.245162\n",
      "13  Attribute14  0.243970\n",
      "12  Attribute13  0.241300\n",
      "15  Attribute16  0.238697\n",
      "6    Attribute7  0.232773\n",
      "23  Attribute24  0.221345\n",
      "33  Attribute34  0.220364\n",
      "14  Attribute15  0.217917\n",
      "22  Attribute23  0.215758\n",
      "31  Attribute32  0.207568\n",
      "24  Attribute25  0.204661\n",
      "21  Attribute22  0.201930\n",
      "8    Attribute9  0.200808\n",
      "3    Attribute4  0.196269\n",
      "25  Attribute26  0.193824\n",
      "17  Attribute18  0.189906\n",
      "9   Attribute10  0.189552\n",
      "11  Attribute12  0.185869\n",
      "19  Attribute20  0.185076\n",
      "27  Attribute28  0.183910\n",
      "10  Attribute11  0.172547\n",
      "18  Attribute19  0.160522\n",
      "29  Attribute30  0.154623\n",
      "16  Attribute17  0.152221\n",
      "0    Attribute1  0.097375\n",
      "1    Attribute2  0.000000\n",
      "Model Accuracy: 0.9295774647887324\n",
      "Feature Rankings using Mutual Information Classification:\n",
      "        Feature     Score\n",
      "5    Attribute6  0.297178\n",
      "4    Attribute5  0.292443\n",
      "7    Attribute8  0.286131\n",
      "20  Attribute21  0.279286\n",
      "26  Attribute27  0.276162\n",
      "32  Attribute33  0.259260\n",
      "30  Attribute31  0.249639\n",
      "28  Attribute29  0.248604\n",
      "2    Attribute3  0.245162\n",
      "13  Attribute14  0.243970\n",
      "12  Attribute13  0.241300\n",
      "15  Attribute16  0.238697\n",
      "6    Attribute7  0.232773\n",
      "23  Attribute24  0.221345\n",
      "33  Attribute34  0.220364\n",
      "14  Attribute15  0.217917\n",
      "22  Attribute23  0.215758\n",
      "31  Attribute32  0.207568\n",
      "24  Attribute25  0.204661\n",
      "21  Attribute22  0.201930\n",
      "8    Attribute9  0.200808\n",
      "3    Attribute4  0.196269\n",
      "25  Attribute26  0.193824\n",
      "17  Attribute18  0.189906\n",
      "9   Attribute10  0.189552\n",
      "11  Attribute12  0.185869\n",
      "19  Attribute20  0.185076\n",
      "27  Attribute28  0.183910\n",
      "10  Attribute11  0.172547\n",
      "18  Attribute19  0.160522\n",
      "29  Attribute30  0.154623\n",
      "16  Attribute17  0.152221\n",
      "0    Attribute1  0.097375\n",
      "1    Attribute2  0.000000\n",
      "Model Accuracy: 0.9295774647887324\n",
      "Feature Rankings using Mutual Information Classification:\n",
      "        Feature     Score\n",
      "5    Attribute6  0.297178\n",
      "4    Attribute5  0.292443\n",
      "7    Attribute8  0.286131\n",
      "20  Attribute21  0.279286\n",
      "26  Attribute27  0.276162\n",
      "32  Attribute33  0.259260\n",
      "30  Attribute31  0.249639\n",
      "28  Attribute29  0.248604\n",
      "2    Attribute3  0.245162\n",
      "13  Attribute14  0.243970\n",
      "12  Attribute13  0.241300\n",
      "15  Attribute16  0.238697\n",
      "6    Attribute7  0.232773\n",
      "23  Attribute24  0.221345\n",
      "33  Attribute34  0.220364\n",
      "14  Attribute15  0.217917\n",
      "22  Attribute23  0.215758\n",
      "31  Attribute32  0.207568\n",
      "24  Attribute25  0.204661\n",
      "21  Attribute22  0.201930\n",
      "8    Attribute9  0.200808\n",
      "3    Attribute4  0.196269\n",
      "25  Attribute26  0.193824\n",
      "17  Attribute18  0.189906\n",
      "9   Attribute10  0.189552\n",
      "11  Attribute12  0.185869\n",
      "19  Attribute20  0.185076\n",
      "27  Attribute28  0.183910\n",
      "10  Attribute11  0.172547\n",
      "18  Attribute19  0.160522\n",
      "29  Attribute30  0.154623\n",
      "16  Attribute17  0.152221\n",
      "0    Attribute1  0.097375\n",
      "1    Attribute2  0.000000\n",
      "Model Accuracy: 0.9295774647887324\n",
      "Feature Rankings using Mutual Information Classification:\n",
      "        Feature     Score\n",
      "5    Attribute6  0.297178\n",
      "4    Attribute5  0.292443\n",
      "7    Attribute8  0.286131\n",
      "20  Attribute21  0.279286\n",
      "26  Attribute27  0.276162\n",
      "32  Attribute33  0.259260\n",
      "30  Attribute31  0.249639\n",
      "28  Attribute29  0.248604\n",
      "2    Attribute3  0.245162\n",
      "13  Attribute14  0.243970\n",
      "12  Attribute13  0.241300\n",
      "15  Attribute16  0.238697\n",
      "6    Attribute7  0.232773\n",
      "23  Attribute24  0.221345\n",
      "33  Attribute34  0.220364\n",
      "14  Attribute15  0.217917\n",
      "22  Attribute23  0.215758\n",
      "31  Attribute32  0.207568\n",
      "24  Attribute25  0.204661\n",
      "21  Attribute22  0.201930\n",
      "8    Attribute9  0.200808\n",
      "3    Attribute4  0.196269\n",
      "25  Attribute26  0.193824\n",
      "17  Attribute18  0.189906\n",
      "9   Attribute10  0.189552\n",
      "11  Attribute12  0.185869\n",
      "19  Attribute20  0.185076\n",
      "27  Attribute28  0.183910\n",
      "10  Attribute11  0.172547\n",
      "18  Attribute19  0.160522\n",
      "29  Attribute30  0.154623\n",
      "16  Attribute17  0.152221\n",
      "0    Attribute1  0.097375\n",
      "1    Attribute2  0.000000\n",
      "Model Accuracy: 0.9295774647887324\n",
      "Best k: 5, Best Accuracy: 0.9295774647887324\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "# Apply Mutual Information Regression (MIR)\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "results = []\n",
    "\n",
    "# Wrapping mutual_info_regression with a fixed random_state\n",
    "mutual_info_regression_with_random_state = lambda X, y: mutual_info_regression(X, y, random_state=42)\n",
    "\n",
    "for k in range(MIN_FEATURES, MAX_FEATURES):\n",
    "  # SelectKBest with mutual_info_regression evaluates all features\n",
    "  X_top = get_top_features_with_selector(\n",
    "      selector=SelectKBest(score_func=mutual_info_regression_with_random_state, k='all'),\n",
    "      num_of_features_to_select=k,\n",
    "      data_with_features=data_after_scaling,\n",
    "      target_variables=target_variables,\n",
    "      algorithm=\"Mutual Information Regression\",\n",
    "      verbose=True\n",
    "  )\n",
    "  # Split the data into train and test sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_top, target_variables, test_size=0.2, random_state=42)\n",
    "\n",
    "  # Train and fit random forest classification model based on feature selected\n",
    "  accuracy = train_and_fit_random_forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "  results.append((k, accuracy))\n",
    "\n",
    "# Find the best k\n",
    "best_k, best_accuracy = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best k: {best_k}, Best Accuracy: {best_accuracy}\")"
   ],
   "metadata": {
    "id": "KvD-1ZX9Ixjf",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1737710403135,
     "user_tz": -120,
     "elapsed": 3,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "ExecuteTime": {
     "end_time": "2025-01-24T20:11:08.049303Z",
     "start_time": "2025-01-24T20:11:07.582758Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'g'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[26], line 11\u001B[0m\n\u001B[0;32m      7\u001B[0m mutual_info_regression_with_random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m X, y: mutual_info_regression(X, y, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(MIN_FEATURES, MAX_FEATURES):\n\u001B[0;32m     10\u001B[0m   \u001B[38;5;66;03m# SelectKBest with mutual_info_regression evaluates all features\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m   X_top \u001B[38;5;241m=\u001B[39m get_top_features_with_selector(\n\u001B[0;32m     12\u001B[0m       selector\u001B[38;5;241m=\u001B[39mSelectKBest(score_func\u001B[38;5;241m=\u001B[39mmutual_info_regression_with_random_state, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m     13\u001B[0m       num_of_features_to_select\u001B[38;5;241m=\u001B[39mk,\n\u001B[0;32m     14\u001B[0m       data_with_features\u001B[38;5;241m=\u001B[39mdata_after_scaling,\n\u001B[0;32m     15\u001B[0m       target_variables\u001B[38;5;241m=\u001B[39mtarget_variables,\n\u001B[0;32m     16\u001B[0m       algorithm\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMutual Information Regression\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m       verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     18\u001B[0m   )\n\u001B[0;32m     19\u001B[0m   \u001B[38;5;66;03m# Split the data into train and test sets\u001B[39;00m\n\u001B[0;32m     20\u001B[0m   X_train, X_test, y_train, y_test \u001B[38;5;241m=\u001B[39m train_test_split(X_top, target_variables, test_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "Cell \u001B[1;32mIn[22], line 17\u001B[0m, in \u001B[0;36mget_top_features_with_selector\u001B[1;34m(selector, num_of_features_to_select, data_with_features, target_variables, algorithm, verbose)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_top_features_with_selector\u001B[39m(selector: SelectKBest,\n\u001B[0;32m      2\u001B[0m                                     num_of_features_to_select: \u001B[38;5;28mint\u001B[39m,\n\u001B[0;32m      3\u001B[0m                                     data_with_features,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m      6\u001B[0m                                     verbose: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m      7\u001B[0m                                     ):\n\u001B[0;32m      8\u001B[0m \u001B[38;5;250m      \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;124;03m      :param selector: SelectKBest object.\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;124;03m      :param num_of_features_to_select:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;124;03m      :return:\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;124;03m      \"\"\"\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m       selector\u001B[38;5;241m.\u001B[39mfit(data_with_features, target_variables)\n\u001B[0;32m     19\u001B[0m       \u001B[38;5;66;03m# Rank the features using Chi-Square algorithm\u001B[39;00m\n\u001B[0;32m     20\u001B[0m       top_features \u001B[38;5;241m=\u001B[39m get_top_k_features(selector\u001B[38;5;241m=\u001B[39mselector, feature_names\u001B[38;5;241m=\u001B[39mfeatures\u001B[38;5;241m.\u001B[39mcolumns,\n\u001B[0;32m     21\u001B[0m                                         top_features_to_select\u001B[38;5;241m=\u001B[39mnum_of_features_to_select, algorithm\u001B[38;5;241m=\u001B[39malgorithm,\n\u001B[0;32m     22\u001B[0m                                         verbose\u001B[38;5;241m=\u001B[39mverbose)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[1;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1466\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m   1468\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[0;32m   1469\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[0;32m   1470\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[0;32m   1471\u001B[0m     )\n\u001B[0;32m   1472\u001B[0m ):\n\u001B[1;32m-> 1473\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m fit_method(estimator, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:567\u001B[0m, in \u001B[0;36m_BaseFilter.fit\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    562\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(\n\u001B[0;32m    563\u001B[0m         X, y, accept_sparse\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m], multi_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    564\u001B[0m     )\n\u001B[0;32m    566\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_params(X, y)\n\u001B[1;32m--> 567\u001B[0m score_func_ret \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscore_func(X, y)\n\u001B[0;32m    568\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(score_func_ret, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m    569\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscores_, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpvalues_ \u001B[38;5;241m=\u001B[39m score_func_ret\n",
      "Cell \u001B[1;32mIn[26], line 7\u001B[0m, in \u001B[0;36m<lambda>\u001B[1;34m(X, y)\u001B[0m\n\u001B[0;32m      4\u001B[0m results \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Wrapping mutual_info_regression with a fixed random_state\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m mutual_info_regression_with_random_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m X, y: mutual_info_regression(X, y, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(MIN_FEATURES, MAX_FEATURES):\n\u001B[0;32m     10\u001B[0m   \u001B[38;5;66;03m# SelectKBest with mutual_info_regression evaluates all features\u001B[39;00m\n\u001B[0;32m     11\u001B[0m   X_top \u001B[38;5;241m=\u001B[39m get_top_features_with_selector(\n\u001B[0;32m     12\u001B[0m       selector\u001B[38;5;241m=\u001B[39mSelectKBest(score_func\u001B[38;5;241m=\u001B[39mmutual_info_regression_with_random_state, k\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m     13\u001B[0m       num_of_features_to_select\u001B[38;5;241m=\u001B[39mk,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     17\u001B[0m       verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     18\u001B[0m   )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:186\u001B[0m, in \u001B[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    184\u001B[0m global_skip_validation \u001B[38;5;241m=\u001B[39m get_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mskip_parameter_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m global_skip_validation:\n\u001B[1;32m--> 186\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    188\u001B[0m func_sig \u001B[38;5;241m=\u001B[39m signature(func)\n\u001B[0;32m    190\u001B[0m \u001B[38;5;66;03m# Map *args/**kwargs to the function signature\u001B[39;00m\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:441\u001B[0m, in \u001B[0;36mmutual_info_regression\u001B[1;34m(X, y, discrete_features, n_neighbors, copy, random_state, n_jobs)\u001B[0m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;129m@validate_params\u001B[39m(\n\u001B[0;32m    326\u001B[0m     {\n\u001B[0;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marray-like\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msparse matrix\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    345\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    346\u001B[0m ):\n\u001B[0;32m    347\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Estimate mutual information for a continuous target variable.\u001B[39;00m\n\u001B[0;32m    348\u001B[0m \n\u001B[0;32m    349\u001B[0m \u001B[38;5;124;03m    Mutual information (MI) [1]_ between two random variables is a non-negative\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    439\u001B[0m \u001B[38;5;124;03m    array([0.1..., 2.6...  , 0.0...])\u001B[39;00m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _estimate_mi(\n\u001B[0;32m    442\u001B[0m         X,\n\u001B[0;32m    443\u001B[0m         y,\n\u001B[0;32m    444\u001B[0m         discrete_features\u001B[38;5;241m=\u001B[39mdiscrete_features,\n\u001B[0;32m    445\u001B[0m         discrete_target\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m    446\u001B[0m         n_neighbors\u001B[38;5;241m=\u001B[39mn_neighbors,\n\u001B[0;32m    447\u001B[0m         copy\u001B[38;5;241m=\u001B[39mcopy,\n\u001B[0;32m    448\u001B[0m         random_state\u001B[38;5;241m=\u001B[39mrandom_state,\n\u001B[0;32m    449\u001B[0m         n_jobs\u001B[38;5;241m=\u001B[39mn_jobs,\n\u001B[0;32m    450\u001B[0m     )\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:271\u001B[0m, in \u001B[0;36m_estimate_mi\u001B[1;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state, n_jobs)\u001B[0m\n\u001B[0;32m    202\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_estimate_mi\u001B[39m(\n\u001B[0;32m    203\u001B[0m     X,\n\u001B[0;32m    204\u001B[0m     y,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    211\u001B[0m     n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    212\u001B[0m ):\n\u001B[0;32m    213\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Estimate mutual information between the features and the target.\u001B[39;00m\n\u001B[0;32m    214\u001B[0m \n\u001B[0;32m    215\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    269\u001B[0m \u001B[38;5;124;03m           Data Sets\". PLoS ONE 9(2), 2014.\u001B[39;00m\n\u001B[0;32m    270\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 271\u001B[0m     X, y \u001B[38;5;241m=\u001B[39m check_X_y(X, y, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsc\u001B[39m\u001B[38;5;124m\"\u001B[39m, y_numeric\u001B[38;5;241m=\u001B[39m\u001B[38;5;129;01mnot\u001B[39;00m discrete_target)\n\u001B[0;32m    272\u001B[0m     n_samples, n_features \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(discrete_features, (\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mbool\u001B[39m)):\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1318\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1297\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1298\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1299\u001B[0m     )\n\u001B[0;32m   1301\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[0;32m   1302\u001B[0m     X,\n\u001B[0;32m   1303\u001B[0m     accept_sparse\u001B[38;5;241m=\u001B[39maccept_sparse,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1315\u001B[0m     input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1316\u001B[0m )\n\u001B[1;32m-> 1318\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[0;32m   1320\u001B[0m check_consistent_length(X, y)\n\u001B[0;32m   1322\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X, y\n",
      "File \u001B[1;32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1343\u001B[0m, in \u001B[0;36m_check_y\u001B[1;34m(y, multi_output, y_numeric, estimator)\u001B[0m\n\u001B[0;32m   1341\u001B[0m     _ensure_no_complex_data(y)\n\u001B[0;32m   1342\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_numeric \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(y\u001B[38;5;241m.\u001B[39mdtype, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkind\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m y\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mO\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m-> 1343\u001B[0m     y \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat64)\n\u001B[0;32m   1345\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m y\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: 'g'"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "# Apply ANOVA F-value Classification\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "results = []\n",
    "for k in range(MIN_FEATURES, MAX_FEATURES):\n",
    "  # SelectKBest with f_classif evaluates all features\n",
    "  X_top = get_top_features_with_selector(\n",
    "      selector=SelectKBest(score_func=f_classif, k='all'),\n",
    "      num_of_features_to_select=k,\n",
    "      data_with_features=data_after_scaling,\n",
    "      target_variables=target_variables,\n",
    "      algorithm=\"ANOVA F-value Classificaiton\",\n",
    "      verbose=True\n",
    "  )\n",
    "  # Split the data into train and test sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_top, target_variables, test_size=0.2, random_state=42)\n",
    "\n",
    "  # Train and fit random forest classification model based on feature selected\n",
    "  accuracy = train_and_fit_random_forest(X_train, X_test, y_train, y_test)\n",
    "\n",
    "  results.append((k, accuracy))\n",
    "\n",
    "# Find the best k\n",
    "best_k, best_accuracy = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best k: {best_k}, Best Accuracy: {best_accuracy}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O9tPxGglO_KN",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737712839445,
     "user_tz": -120,
     "elapsed": 202652,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "outputId": "80c0c6a7-d3d8-403f-a172-e0ed17948f48"
   },
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Accuracy: 0.23333333333333334\n",
      "Model Accuracy: 0.2865384615384615\n",
      "Model Accuracy: 0.30833333333333335\n",
      "Model Accuracy: 0.46282051282051284\n",
      "Model Accuracy: 0.4980769230769231\n",
      "Model Accuracy: 0.5121794871794871\n",
      "Model Accuracy: 0.5487179487179488\n",
      "Model Accuracy: 0.5666666666666667\n",
      "Model Accuracy: 0.5858974358974359\n",
      "Model Accuracy: 0.6217948717948718\n",
      "Model Accuracy: 0.6384615384615384\n",
      "Model Accuracy: 0.6435897435897436\n",
      "Model Accuracy: 0.6724358974358975\n",
      "Model Accuracy: 0.6826923076923077\n",
      "Model Accuracy: 0.683974358974359\n",
      "Model Accuracy: 0.6948717948717948\n",
      "Model Accuracy: 0.6993589743589743\n",
      "Model Accuracy: 0.7153846153846154\n",
      "Model Accuracy: 0.7352564102564103\n",
      "Model Accuracy: 0.7448717948717949\n",
      "Model Accuracy: 0.7416666666666667\n",
      "Model Accuracy: 0.7487179487179487\n",
      "Model Accuracy: 0.757051282051282\n",
      "Model Accuracy: 0.7480769230769231\n",
      "Model Accuracy: 0.757051282051282\n",
      "Model Accuracy: 0.7583333333333333\n",
      "Model Accuracy: 0.7628205128205128\n",
      "Model Accuracy: 0.7705128205128206\n",
      "Model Accuracy: 0.7660256410256411\n",
      "Model Accuracy: 0.7698717948717949\n",
      "Model Accuracy: 0.7660256410256411\n",
      "Model Accuracy: 0.7698717948717949\n",
      "Model Accuracy: 0.767948717948718\n",
      "Model Accuracy: 0.7602564102564102\n",
      "Model Accuracy: 0.7737179487179487\n",
      "Model Accuracy: 0.7807692307692308\n",
      "Model Accuracy: 0.7788461538461539\n",
      "Model Accuracy: 0.7794871794871795\n",
      "Model Accuracy: 0.7865384615384615\n",
      "Model Accuracy: 0.7955128205128205\n",
      "Model Accuracy: 0.8070512820512821\n",
      "Model Accuracy: 0.8128205128205128\n",
      "Model Accuracy: 0.8179487179487179\n",
      "Model Accuracy: 0.8153846153846154\n",
      "Model Accuracy: 0.8121794871794872\n",
      "Model Accuracy: 0.8224358974358974\n",
      "Best k: 50, Best Accuracy: 0.8224358974358974\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Apply ANOVA F-value Regression\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "results = []\n",
    "for k in range(MIN_FEATURES, MAX_FEATURES):\n",
    "  # SelectKBest with f_regression evaluates all features\n",
    "  X_top = get_top_features_with_selector(\n",
    "      selector=SelectKBest(score_func=f_regression, k='all'),\n",
    "      num_of_features_to_select=k,\n",
    "      data_with_features=data_after_scaling,\n",
    "      target_variables=target_variables,\n",
    "      algorithm=\"ANOVA F-value Regression\",\n",
    "      verbose=True\n",
    "  )\n",
    "  # Split the data into train and test sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X_top, target_variables, test_size=0.2, random_state=42)\n",
    "\n",
    "  # Train and fit random forest classification model based on feature selected\n",
    "  accuracy = train_and_fit_random_forest(X_train, X_test, y_train, y_test)\n",
    "  results.append((k, accuracy))\n",
    "\n",
    "# Find the best k\n",
    "best_k, best_accuracy = max(results, key=lambda x: x[1])\n",
    "\n",
    "print(f\"Best k: {best_k}, Best Accuracy: {best_accuracy}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6g17o-1HQmBp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737713873092,
     "user_tz": -120,
     "elapsed": 270905,
     "user": {
      "displayName": "תומר וסרמן",
      "userId": "13570990899464465396"
     }
    },
    "outputId": "dc0d89ca-e9fe-4a0a-e8c9-a9276fd2651a"
   },
   "execution_count": 62,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Accuracy: 0.258974358974359\n",
      "Model Accuracy: 0.30512820512820515\n",
      "Model Accuracy: 0.35512820512820514\n",
      "Model Accuracy: 0.4025641025641026\n",
      "Model Accuracy: 0.46025641025641023\n",
      "Model Accuracy: 0.48012820512820514\n",
      "Model Accuracy: 0.5012820512820513\n",
      "Model Accuracy: 0.5032051282051282\n",
      "Model Accuracy: 0.517948717948718\n",
      "Model Accuracy: 0.5352564102564102\n",
      "Model Accuracy: 0.5365384615384615\n",
      "Model Accuracy: 0.5307692307692308\n",
      "Model Accuracy: 0.5371794871794872\n",
      "Model Accuracy: 0.5551282051282052\n",
      "Model Accuracy: 0.5532051282051282\n",
      "Model Accuracy: 0.5814102564102565\n",
      "Model Accuracy: 0.5897435897435898\n",
      "Model Accuracy: 0.6006410256410256\n",
      "Model Accuracy: 0.6\n",
      "Model Accuracy: 0.6057692307692307\n",
      "Model Accuracy: 0.6006410256410256\n",
      "Model Accuracy: 0.6044871794871794\n",
      "Model Accuracy: 0.610897435897436\n",
      "Model Accuracy: 0.6121794871794872\n",
      "Model Accuracy: 0.610897435897436\n",
      "Model Accuracy: 0.6102564102564103\n",
      "Model Accuracy: 0.6147435897435898\n",
      "Model Accuracy: 0.6141025641025641\n",
      "Model Accuracy: 0.6185897435897436\n",
      "Model Accuracy: 0.6205128205128205\n",
      "Model Accuracy: 0.6442307692307693\n",
      "Model Accuracy: 0.6358974358974359\n",
      "Model Accuracy: 0.6410256410256411\n",
      "Model Accuracy: 0.6358974358974359\n",
      "Model Accuracy: 0.642948717948718\n",
      "Model Accuracy: 0.6435897435897436\n",
      "Model Accuracy: 0.6435897435897436\n",
      "Model Accuracy: 0.6448717948717949\n",
      "Model Accuracy: 0.6544871794871795\n",
      "Model Accuracy: 0.6525641025641026\n",
      "Model Accuracy: 0.6455128205128206\n",
      "Model Accuracy: 0.6544871794871795\n",
      "Model Accuracy: 0.6544871794871795\n",
      "Model Accuracy: 0.6833333333333333\n",
      "Model Accuracy: 0.683974358974359\n",
      "Model Accuracy: 0.6807692307692308\n",
      "Best k: 49, Best Accuracy: 0.683974358974359\n"
     ]
    }
   ]
  }
 ]
}
