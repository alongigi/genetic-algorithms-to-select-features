{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Askn1naxHZmU"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# # Upload the file\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XGNktFp1Znk",
        "outputId": "d5363662-7c3a-40f4-f5fe-66f3443703a4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ucimlrepo in /usr/local/lib/python3.11/dist-packages (0.0.7)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2024.12.14)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "CeNLwRfGHPGj"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 1: Load your dataset\n",
        "# data = pd.read_csv('heart_attack_risk_dataset.csv')"
      ],
      "metadata": {
        "id": "GhoKtv7bw0zG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 2: Separate features (X) and target (y)\n",
        "# TARGET_VARIABLE = 'Heart_Attack_Risk'\n",
        "# X = data.drop(columns=[TARGET_VARIABLE])\n",
        "# y = data[TARGET_VARIABLE]"
      ],
      "metadata": {
        "id": "8xWFEramzQWL"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Step 3: Identify and encode categorical columns\n",
        "\n",
        "# # Identify categorical\n",
        "# categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "\n",
        "# # Step 3: Encode categorical columns\n",
        "# label_encoders = {}\n",
        "# for col in categorical_cols:\n",
        "#     le = LabelEncoder()\n",
        "#     X[col] = le.fit_transform(X[col])\n",
        "#     label_encoders[col] = le\n",
        "\n",
        "# # Encode the target variable as well\n",
        "# y = LabelEncoder().fit_transform(y)"
      ],
      "metadata": {
        "id": "7RkfM8W34UJU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "isolet = fetch_ucirepo(id=54)\n",
        "\n",
        "X = isolet.data.features\n",
        "y = isolet.data.targets"
      ],
      "metadata": {
        "id": "831UY6sF1VGr"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_df = pd.DataFrame(X)\n",
        "y_df = pd.DataFrame(y)\n",
        "\n",
        "print(\"Missing values in X:\", X_df.isnull().sum().sum())\n",
        "print(\"Missing values in y:\", y_df.isnull().sum().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Rboy6231cUe",
        "outputId": "d33ad17f-b863-4d14-8777-cd762ff61e14"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values in X: 0\n",
            "Missing values in y: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Minimum value across all features:\", X_df.min().min())\n",
        "print(\"Maximum value across all features:\", X_df.max().max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQ2t-xmX1gZr",
        "outputId": "b2f5b21a-b308-4ae2-a60a-c4e21f5eb67c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum value across all features: -1.0\n",
            "Maximum value across all features: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X_df)\n",
        "\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X_df.columns)\n",
        "\n",
        "print(X_scaled_df.min().min())\n",
        "print(X_scaled_df.max().max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBcbgk7w2c7E",
        "outputId": "40393dad-be4b-4d83-cb15-a5d184e3aa81"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "1.0000000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# spambase = fetch_ucirepo(id=94)\n",
        "\n",
        "# X = spambase.data.features\n",
        "# y = spambase.data.targets"
      ],
      "metadata": {
        "id": "Wlf7bg941hFa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_df = pd.DataFrame(X)\n",
        "# y_df = pd.DataFrame(y)\n",
        "\n",
        "# print(\"Missing values in X:\", X_df.isnull().sum().sum())\n",
        "# print(\"Missing values in y:\", y_df.isnull().sum().sum())"
      ],
      "metadata": {
        "id": "ab-7qizw1hJk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Minimum value across all features:\", X_df.min().min())\n",
        "# print(\"Maximum value across all features:\", X_df.max().max())"
      ],
      "metadata": {
        "id": "ir1RswI21hMe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaler = MinMaxScaler()\n",
        "# X_scaled = scaler.fit_transform(X_df)\n",
        "\n",
        "# X_scaled_df = pd.DataFrame(X_scaled, columns=X_df.columns)\n",
        "\n",
        "# print(X_scaled_df.min().min())\n",
        "# print(X_scaled_df.max().max())"
      ],
      "metadata": {
        "id": "EpYHlOi21oLl"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_scaled_df\n",
        "y = y_df"
      ],
      "metadata": {
        "id": "ln9AGKEp13MB"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_k_features(selector, feature_names, k, algorithm):\n",
        "  \"\"\"\n",
        "  Get the top k features based on their scores from a SelectKBest selector.\n",
        "\n",
        "  Parameters:\n",
        "  selector (SelectKBest): Fitted SelectKBest object.\n",
        "  feature_names (list): List of feature names (columns of X).\n",
        "  k (int): Number of top features to select.\n",
        "  algorithm (str): The name of the feature selection algorithm.\n",
        "\n",
        "  Returns:\n",
        "  list: Names of the top k features.\n",
        "  \"\"\"\n",
        "  # Retrieve feature scores\n",
        "  scores = selector.scores_\n",
        "\n",
        "  # Create a DataFrame for ranked features\n",
        "  feature_ranking = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Score': scores\n",
        "  }).sort_values(by='Score', ascending=False)\n",
        "\n",
        "  # Display top-ranked features\n",
        "  print(f\"Feature Rankings using {algorithm}:\")\n",
        "  print(feature_ranking)\n",
        "\n",
        "  # Return selected top k features\n",
        "  return feature_ranking.head(k)['Feature'].tolist()"
      ],
      "metadata": {
        "id": "qIJoIpIA_uOj"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_fit_model(X_train, X_test, y_train, y_test):\n",
        "  \"\"\"\n",
        "  Builds, trains, and evaluates a Random Forest classification model.\n",
        "\n",
        "  Parameters:\n",
        "  ----------\n",
        "  X_train : pd.DataFrame or np.ndarray\n",
        "      Feature matrix for training the model.\n",
        "  X_test : pd.DataFrame or np.ndarray\n",
        "      Feature matrix for testing the model.\n",
        "  y_train : pd.Series or np.ndarray\n",
        "      Target labels for training the model.\n",
        "  y_test : pd.Series or np.ndarray\n",
        "      True target labels for testing the model.\n",
        "\n",
        "  Returns:\n",
        "  -------\n",
        "  None\n",
        "      Prints the model's accuracy and a detailed classification report.\n",
        "  \"\"\"\n",
        "  # Build a simple classification model\n",
        "  model = RandomForestClassifier(random_state=42)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  # Make predictions\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # Evaluate the model\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(\"\\nModel Accuracy with Top 10 Features:\", accuracy)\n",
        "\n",
        "  # Detailed performance metrics\n",
        "  print(\"\\nClassification Report:\")\n",
        "  print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "3xTJU8bjG8IN"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "# Step 4: Apply Chi-Square\n",
        "\n",
        "# SelectKBest with chi2 evaluates all features\n",
        "selector = SelectKBest(score_func=chi2, k='all')\n",
        "selector.fit(X, y)\n",
        "\n",
        "# Rank the features using Chi-Square algorithm\n",
        "top_features = get_top_k_features(selector=selector, feature_names=X.columns,\n",
        "                                  k=20, algorithm=\"Chi-Square\")\n",
        "\n",
        "# Reduce the dataset to the top 10 features\n",
        "X_top = X[top_features]\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and fit random forest classification model based on feature selected\n",
        "train_and_fit_model(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUWXWxKB4ifL",
        "outputId": "f09dc994-0bcc-4b83-b487-918eb2b80f7b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Rankings using Chi-Square:\n",
            "          Feature        Score\n",
            "418  Attribute419  5041.889698\n",
            "417  Attribute418  4948.081234\n",
            "416  Attribute417  4712.209974\n",
            "415  Attribute416  4316.661306\n",
            "388  Attribute389  4286.109851\n",
            "..            ...          ...\n",
            "601  Attribute602    35.166998\n",
            "344  Attribute345    32.509363\n",
            "600  Attribute601    31.842739\n",
            "343  Attribute344    27.478685\n",
            "472  Attribute473    14.244934\n",
            "\n",
            "[617 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy with Top 10 Features: 0.39294871794871794\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.06      0.05      0.05        66\n",
            "         2.0       0.15      0.16      0.16        50\n",
            "         3.0       0.82      0.79      0.80        62\n",
            "         4.0       0.12      0.08      0.10        59\n",
            "         5.0       0.06      0.05      0.05        64\n",
            "         6.0       0.78      0.90      0.83        59\n",
            "         7.0       0.28      0.28      0.28        53\n",
            "         8.0       0.92      0.81      0.86        70\n",
            "         9.0       0.09      0.11      0.10        56\n",
            "        10.0       0.25      0.31      0.28        55\n",
            "        11.0       0.64      0.47      0.54        78\n",
            "        12.0       0.06      0.04      0.05        67\n",
            "        13.0       0.11      0.12      0.11        58\n",
            "        14.0       0.10      0.11      0.10        66\n",
            "        15.0       0.15      0.20      0.17        54\n",
            "        16.0       0.43      0.49      0.46        59\n",
            "        17.0       0.45      0.50      0.47        60\n",
            "        18.0       0.11      0.13      0.12        52\n",
            "        19.0       0.97      0.90      0.93        62\n",
            "        20.0       0.52      0.48      0.50        54\n",
            "        21.0       0.06      0.06      0.06        51\n",
            "        22.0       0.48      0.60      0.53        57\n",
            "        23.0       0.46      0.50      0.48        54\n",
            "        24.0       0.86      0.95      0.90        58\n",
            "        25.0       0.30      0.23      0.26        69\n",
            "        26.0       0.72      0.73      0.73        67\n",
            "\n",
            "    accuracy                           0.39      1560\n",
            "   macro avg       0.38      0.39      0.38      1560\n",
            "weighted avg       0.39      0.39      0.39      1560\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_classif\n",
        "# Step 5: Apply Mutual Information Classification (MIC)\n",
        "\n",
        "# Wrapping mutual_info_classif with a fixed random_state\n",
        "mutual_info_classif_with_random_state = lambda X, y: mutual_info_classif(X, y, random_state=42)\n",
        "\n",
        "# SelectKBest with mutual_info_classif evaluates all features\n",
        "selector = SelectKBest(score_func=mutual_info_classif_with_random_state, k='all')\n",
        "selector.fit(X, y)\n",
        "\n",
        "# Rank the features using Mutual Information Classification algorithm\n",
        "top_features = get_top_k_features(selector=selector, feature_names=X.columns,\n",
        "                                  k=20, algorithm=\"Mutual Information Classification\")\n",
        "\n",
        "# Reduce the dataset to the top 10 features\n",
        "X_top = X[top_features]\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and fit random forest classification model based on feature selected\n",
        "train_and_fit_model(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUgKQV416YIo",
        "outputId": "88332561-d785-48cc-d901-58f0dbbcf799"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Rankings using Mutual Information Classification:\n",
            "          Feature     Score\n",
            "461  Attribute462  0.851708\n",
            "460  Attribute461  0.770072\n",
            "105  Attribute106  0.754416\n",
            "104  Attribute105  0.742367\n",
            "459  Attribute460  0.735609\n",
            "..            ...       ...\n",
            "287  Attribute288  0.063881\n",
            "601  Attribute602  0.061680\n",
            "582  Attribute583  0.060256\n",
            "374  Attribute375  0.059147\n",
            "472  Attribute473  0.038452\n",
            "\n",
            "[617 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy with Top 10 Features: 0.642948717948718\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.54      0.67      0.60        66\n",
            "         2.0       0.42      0.56      0.48        50\n",
            "         3.0       0.79      0.87      0.83        62\n",
            "         4.0       0.72      0.78      0.75        59\n",
            "         5.0       0.49      0.31      0.38        64\n",
            "         6.0       0.32      0.32      0.32        59\n",
            "         7.0       0.61      0.79      0.69        53\n",
            "         8.0       0.58      0.54      0.56        70\n",
            "         9.0       0.50      0.61      0.55        56\n",
            "        10.0       0.84      0.85      0.85        55\n",
            "        11.0       0.91      0.86      0.88        78\n",
            "        12.0       0.69      0.60      0.64        67\n",
            "        13.0       0.82      0.78      0.80        58\n",
            "        14.0       0.71      0.68      0.70        66\n",
            "        15.0       0.71      0.72      0.72        54\n",
            "        16.0       0.60      0.61      0.61        59\n",
            "        17.0       0.86      0.85      0.86        60\n",
            "        18.0       0.58      0.73      0.64        52\n",
            "        19.0       0.25      0.18      0.21        62\n",
            "        20.0       0.60      0.65      0.62        54\n",
            "        21.0       0.84      0.90      0.87        51\n",
            "        22.0       0.41      0.32      0.36        57\n",
            "        23.0       0.77      0.69      0.73        54\n",
            "        24.0       0.34      0.38      0.36        58\n",
            "        25.0       0.91      0.84      0.87        69\n",
            "        26.0       0.81      0.64      0.72        67\n",
            "\n",
            "    accuracy                           0.64      1560\n",
            "   macro avg       0.64      0.64      0.64      1560\n",
            "weighted avg       0.64      0.64      0.64      1560\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import mutual_info_regression\n",
        "# Step 6: Apply Mutual Information Regression (MIR)\n",
        "\n",
        "# Wrapping mutual_info_regression with a fixed random_state\n",
        "mutual_info_regression_with_random_state = lambda X, y: mutual_info_regression(X, y, random_state=42)\n",
        "\n",
        "# SelectKBest with mutual_info_regression evaluates all features\n",
        "selector = SelectKBest(score_func=mutual_info_regression_with_random_state, k='all')\n",
        "selector.fit(X, y)\n",
        "\n",
        "# Rank the features using Mutual Information Regression algorithm\n",
        "top_features = get_top_k_features(selector=selector, feature_names=X.columns,\n",
        "                                  k=20, algorithm=\"Mutual Information Regression\")\n",
        "\n",
        "# Reduce the dataset to the top 10 features\n",
        "X_top = X[top_features]\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and fit random forest classification model based on feature selected\n",
        "train_and_fit_model(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvD-1ZX9Ixjf",
        "outputId": "0f9ffb2a-65fc-4b89-a219-5a1f80f34947"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Rankings using Mutual Information Regression:\n",
            "          Feature     Score\n",
            "461  Attribute462  0.854961\n",
            "460  Attribute461  0.765855\n",
            "459  Attribute460  0.756661\n",
            "105  Attribute106  0.755056\n",
            "104  Attribute105  0.742452\n",
            "..            ...       ...\n",
            "601  Attribute602  0.065317\n",
            "287  Attribute288  0.063761\n",
            "582  Attribute583  0.060540\n",
            "374  Attribute375  0.058239\n",
            "472  Attribute473  0.032411\n",
            "\n",
            "[617 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy with Top 10 Features: 0.6621794871794872\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.60      0.65      0.62        66\n",
            "         2.0       0.44      0.60      0.51        50\n",
            "         3.0       0.79      0.84      0.81        62\n",
            "         4.0       0.69      0.76      0.73        59\n",
            "         5.0       0.49      0.30      0.37        64\n",
            "         6.0       0.43      0.34      0.38        59\n",
            "         7.0       0.60      0.75      0.67        53\n",
            "         8.0       0.60      0.61      0.61        70\n",
            "         9.0       0.54      0.70      0.61        56\n",
            "        10.0       0.84      0.87      0.86        55\n",
            "        11.0       0.89      0.87      0.88        78\n",
            "        12.0       0.75      0.61      0.67        67\n",
            "        13.0       0.83      0.83      0.83        58\n",
            "        14.0       0.75      0.71      0.73        66\n",
            "        15.0       0.73      0.74      0.73        54\n",
            "        16.0       0.57      0.56      0.56        59\n",
            "        17.0       0.89      0.83      0.86        60\n",
            "        18.0       0.56      0.73      0.63        52\n",
            "        19.0       0.37      0.26      0.30        62\n",
            "        20.0       0.65      0.69      0.67        54\n",
            "        21.0       0.80      0.92      0.85        51\n",
            "        22.0       0.44      0.35      0.39        57\n",
            "        23.0       0.85      0.74      0.79        54\n",
            "        24.0       0.39      0.52      0.44        58\n",
            "        25.0       0.89      0.81      0.85        69\n",
            "        26.0       0.77      0.64      0.70        67\n",
            "\n",
            "    accuracy                           0.66      1560\n",
            "   macro avg       0.66      0.66      0.66      1560\n",
            "weighted avg       0.66      0.66      0.66      1560\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import f_classif\n",
        "# Step 7: Apply ANOVA F-value Classificaiton\n",
        "\n",
        "# SelectKBest with f_classif evaluates all features\n",
        "selector = SelectKBest(score_func=f_classif, k='all')\n",
        "selector.fit(X, y)\n",
        "\n",
        "# Rank the features using ANOVA F-value Classificaiton algorithm\n",
        "top_features = get_top_k_features(selector=selector, feature_names=X.columns,\n",
        "                                  k=20, algorithm=\"ANOVA F-value Classificaiton\")\n",
        "\n",
        "# Reduce the dataset to the top 10 features\n",
        "X_top = X[top_features]\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and fit random forest classification model based on feature selected\n",
        "train_and_fit_model(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9tPxGglO_KN",
        "outputId": "02d5bf2a-a721-45bb-d54b-ee525517f213"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Rankings using ANOVA F-value Classificaiton:\n",
            "          Feature        Score\n",
            "418  Attribute419  3746.378688\n",
            "417  Attribute418  3470.067861\n",
            "416  Attribute417  2645.365726\n",
            "394  Attribute395  2338.155556\n",
            "415  Attribute416  1928.357789\n",
            "..            ...          ...\n",
            "346  Attribute347    17.850687\n",
            "343  Attribute344    16.862710\n",
            "345  Attribute346    16.335827\n",
            "344  Attribute345    14.390236\n",
            "472  Attribute473     4.741746\n",
            "\n",
            "[617 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy with Top 10 Features: 0.6948717948717948\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.77      0.83      0.80        66\n",
            "         2.0       0.39      0.60      0.47        50\n",
            "         3.0       0.82      0.79      0.80        62\n",
            "         4.0       0.55      0.49      0.52        59\n",
            "         5.0       0.31      0.25      0.28        64\n",
            "         6.0       0.85      0.90      0.88        59\n",
            "         7.0       0.59      0.75      0.66        53\n",
            "         8.0       0.94      0.91      0.93        70\n",
            "         9.0       0.47      0.52      0.49        56\n",
            "        10.0       0.74      0.82      0.78        55\n",
            "        11.0       0.82      0.79      0.81        78\n",
            "        12.0       0.80      0.67      0.73        67\n",
            "        13.0       0.77      0.76      0.77        58\n",
            "        14.0       0.74      0.64      0.68        66\n",
            "        15.0       0.62      0.69      0.65        54\n",
            "        16.0       0.58      0.64      0.61        59\n",
            "        17.0       0.86      0.82      0.84        60\n",
            "        18.0       0.46      0.60      0.52        52\n",
            "        19.0       0.75      0.84      0.79        62\n",
            "        20.0       0.79      0.61      0.69        54\n",
            "        21.0       0.80      0.88      0.84        51\n",
            "        22.0       0.67      0.53      0.59        57\n",
            "        23.0       0.79      0.78      0.79        54\n",
            "        24.0       0.80      0.69      0.74        58\n",
            "        25.0       0.70      0.55      0.62        69\n",
            "        26.0       0.73      0.69      0.71        67\n",
            "\n",
            "    accuracy                           0.69      1560\n",
            "   macro avg       0.70      0.69      0.69      1560\n",
            "weighted avg       0.70      0.69      0.70      1560\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import f_regression\n",
        "# Step 8: Apply ANOVA F-value Regression\n",
        "\n",
        "# SelectKBest with f_regression evaluates all features\n",
        "selector = SelectKBest(score_func=f_regression, k='all')\n",
        "selector.fit(X, y)\n",
        "\n",
        "# Rank the features using ANOVA F-value Classificaiton algorithm\n",
        "top_features = get_top_k_features(selector=selector, feature_names=X.columns,\n",
        "                                  k=20, algorithm=\"ANOVA F-value Regression\")\n",
        "\n",
        "# Reduce the dataset to the top 10 features\n",
        "X_top = X[top_features]\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_top, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train and fit random forest classification model based on feature selected\n",
        "train_and_fit_model(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g17o-1HQmBp",
        "outputId": "e1e8aaff-1479-49c9-9306-9c45c6ec1e91"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Rankings using ANOVA F-value Regression:\n",
            "          Feature        Score\n",
            "479  Attribute480  1167.843722\n",
            "432  Attribute433   901.785579\n",
            "429  Attribute430   741.821940\n",
            "169  Attribute170   732.346687\n",
            "168  Attribute169   702.084490\n",
            "..            ...          ...\n",
            "66    Attribute67     0.012371\n",
            "565  Attribute566     0.003878\n",
            "44    Attribute45     0.001380\n",
            "582  Attribute583     0.000094\n",
            "344  Attribute345     0.000028\n",
            "\n",
            "[617 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:1408: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model Accuracy with Top 10 Features: 0.5814102564102565\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.37      0.21      0.27        66\n",
            "         2.0       0.24      0.34      0.28        50\n",
            "         3.0       0.44      0.69      0.54        62\n",
            "         4.0       0.31      0.47      0.37        59\n",
            "         5.0       0.45      0.38      0.41        64\n",
            "         6.0       0.61      0.66      0.63        59\n",
            "         7.0       0.29      0.26      0.28        53\n",
            "         8.0       0.36      0.29      0.32        70\n",
            "         9.0       0.83      0.86      0.84        56\n",
            "        10.0       0.35      0.45      0.40        55\n",
            "        11.0       0.54      0.41      0.47        78\n",
            "        12.0       0.69      0.81      0.74        67\n",
            "        13.0       0.75      0.76      0.75        58\n",
            "        14.0       0.71      0.68      0.70        66\n",
            "        15.0       0.79      0.78      0.79        54\n",
            "        16.0       0.52      0.49      0.50        59\n",
            "        17.0       0.75      0.65      0.70        60\n",
            "        18.0       0.91      0.96      0.93        52\n",
            "        19.0       0.57      0.42      0.48        62\n",
            "        20.0       0.28      0.13      0.18        54\n",
            "        21.0       0.71      0.78      0.75        51\n",
            "        22.0       0.46      0.49      0.47        57\n",
            "        23.0       0.82      0.69      0.75        54\n",
            "        24.0       0.62      0.78      0.69        58\n",
            "        25.0       0.93      0.90      0.91        69\n",
            "        26.0       0.85      0.82      0.83        67\n",
            "\n",
            "    accuracy                           0.58      1560\n",
            "   macro avg       0.58      0.58      0.58      1560\n",
            "weighted avg       0.58      0.58      0.58      1560\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-T9O3Jrd3MkD"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}