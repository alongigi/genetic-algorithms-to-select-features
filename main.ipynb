{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-25T09:12:44.789554Z",
     "start_time": "2025-01-25T09:12:41.304786Z"
    }
   },
   "source": [
    "!pip install ucimlrepo\n",
    "!pip install pygad"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ucimlrepo in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: pandas>=1.0.0 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from ucimlrepo) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2020.12.5 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from ucimlrepo) (2024.12.14)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pandas>=1.0.0->ucimlrepo) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
      "Requirement already satisfied: pygad in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (3.4.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pygad) (3.1.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pygad) (3.10.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from pygad) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from matplotlib->pygad) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from matplotlib->pygad) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from matplotlib->pygad) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from matplotlib->pygad) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from matplotlib->pygad) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from matplotlib->pygad) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from matplotlib->pygad) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from matplotlib->pygad) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aviv metz\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->pygad) (1.16.0)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:41.326284Z",
     "start_time": "2025-01-25T09:14:41.323547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pygad\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n"
   ],
   "id": "2bec33f7cae768a4",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:41.334131Z",
     "start_time": "2025-01-25T09:14:41.331273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Indexes of relevant databases.\n",
    "ISOLET_DB_INDEX: int = 54\n",
    "SPAMBASE_DB_INDEX: int = 94"
   ],
   "id": "775d6e9179d6b50f",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Change the following to true for much more robust error messages.",
   "id": "5b5a14b277f5a9c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:41.349300Z",
     "start_time": "2025-01-25T09:14:41.346502Z"
    }
   },
   "cell_type": "code",
   "source": "VERBOSE: bool = False # For more robust error messages",
   "id": "ef2652aa59d70ba5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importing and handling the dataset:",
   "id": "427827ac8230572d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.445774Z",
     "start_time": "2025-01-25T09:14:41.360274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read dataset\n",
    "dataset_currently_used = fetch_ucirepo(id=52)\n",
    "\n",
    "features = dataset_currently_used.data.features\n",
    "target_variables = dataset_currently_used.data.targets"
   ],
   "id": "8e3653a86502cc81",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.454870Z",
     "start_time": "2025-01-25T09:14:43.449766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print missing values and maximum and minimum values in the features of the first dataset\n",
    "X_df = pd.DataFrame(features)\n",
    "y_df = pd.DataFrame(target_variables)\n",
    "\n",
    "print(\"Missing values in X:\", X_df.isnull().sum().sum())\n",
    "print(\"Missing values in y:\", y_df.isnull().sum().sum())\n",
    "\n",
    "print(\"Minimum value across all features:\", X_df.min().min())\n",
    "print(\"Maximum value across all features:\", X_df.max().max())"
   ],
   "id": "5d33b31bad0421c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X: 0\n",
      "Missing values in y: 0\n",
      "Minimum value across all features: -1.0\n",
      "Maximum value across all features: 1.0\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.492112Z",
     "start_time": "2025-01-25T09:14:43.486120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalize the dataset\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X_df)\n",
    "\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X_df.columns)\n",
    "\n",
    "print(X_scaled_df.min().min())\n",
    "print(X_scaled_df.max().max())"
   ],
   "id": "64313dee7d6054df",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.529931Z",
     "start_time": "2025-01-25T09:14:43.527571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_after_scaling = X_scaled_df\n",
    "target_variables = y_df.values.ravel()"
   ],
   "id": "88c0991ca7f0b398",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Feature selection functions",
   "id": "4121de36c96f5cba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.571928Z",
     "start_time": "2025-01-25T09:14:43.567944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_top_k_features(selector,\n",
    "                       feature_names: list,\n",
    "                       top_features_to_select: int,\n",
    "                       algorithm: str,\n",
    "                       verbose: bool = False,\n",
    "                       normalize_score: bool = True):\n",
    "  \"\"\"\n",
    "  Get the top k features based on their scores from a SelectKBest selector.\n",
    "\n",
    "  Parameters:\n",
    "  selector (SelectKBest): Fitted SelectKBest object.\n",
    "  feature_names (list): List of feature names (columns of X).\n",
    "  k (int): Number of top features to select.\n",
    "  algorithm (str): The name of the feature selection algorithm.\n",
    "\n",
    "  Returns:\n",
    "  A dataframe that contains 2 columns: The first is \"Feature\" and is the feature name and the second is a score, normalization is dependent on the var sent..\n",
    "\n",
    "  \"\"\"\n",
    "  # Retrieve feature scores\n",
    "  scores = selector.scores_\n",
    "\n",
    "  if normalize_score:\n",
    "      scores = scores / np.nansum(scores)\n",
    "\n",
    "  feature_ranking = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Score': scores\n",
    "  }).sort_values(by='Score', ascending=False)\n",
    "  if verbose:\n",
    "    # Display top-ranked features\n",
    "    print(f\"Feature Rankings using {algorithm}:\")\n",
    "    print(feature_ranking)\n",
    "\n",
    "\n",
    "  # Return selected top k features\n",
    "  return feature_ranking.head(top_features_to_select)"
   ],
   "id": "641eabc4d83c5a34",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.612237Z",
     "start_time": "2025-01-25T09:14:43.609828Z"
    }
   },
   "cell_type": "code",
   "source": "RANDOM_FOREST_SEED: int = 42",
   "id": "d0071fc97b791c87",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.653137Z",
     "start_time": "2025-01-25T09:14:43.649606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_fit_random_forest(X_train, X_test, y_train, y_test, verbose: bool = VERBOSE):\n",
    "  \"\"\"\n",
    "  Builds, trains, and evaluates a Random Forest classification model.\n",
    "\n",
    "  Parameters:\n",
    "  ----------\n",
    "  X_train : pd.DataFrame or np.ndarray\n",
    "      Feature matrix for training the model.\n",
    "  X_test : pd.DataFrame or np.ndarray\n",
    "      Feature matrix for testing the model.\n",
    "  y_train : pd.Series or np.ndarray\n",
    "      Target labels for training the model.\n",
    "  y_test : pd.Series or np.ndarray\n",
    "      True target labels for testing the model.\n",
    "\n",
    "  Returns:\n",
    "  float: The accuracy of the model on the selected features\n",
    "  \"\"\"\n",
    "  # Build a simple classification model\n",
    "  model = RandomForestClassifier(random_state=RANDOM_FOREST_SEED)\n",
    "  model.fit(X_train, y_train)\n",
    "\n",
    "  # Make predictions\n",
    "  y_pred = model.predict(X_test)\n",
    "\n",
    "  # Evaluate the model\n",
    "  accuracy = accuracy_score(y_test, y_pred)\n",
    "  if verbose:\n",
    "    print(\"Model Accuracy:\", accuracy)\n",
    "    # Detailed performance metrics\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "  # Return the accuracy of the model\n",
    "  return accuracy\n"
   ],
   "id": "b8a8d5a8331edcf9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.693078Z",
     "start_time": "2025-01-25T09:14:43.690624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MIN_FEATURES: int = 5\n",
    "MAX_FEATURES: int = 10\n",
    "TRAIN_TEST_SPLIT_RATIO: float = 0.2\n"
   ],
   "id": "60656a67680f31c3",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import all the feature selection algorithms.",
   "id": "fedf31d48d2d5d3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.734115Z",
     "start_time": "2025-01-25T09:14:43.730367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "mutual_info_classif_with_random_state = lambda X, y: mutual_info_classif(X, y, random_state=42)\n",
    "mutual_info_regression_with_random_state = lambda X, y: mutual_info_regression(X, y, random_state=42)\n",
    "\n",
    "# Selects features based on the k best scores. Here k is 'all'.\n",
    "classifier_chi2: SelectKBest = SelectKBest(score_func=chi2, k='all')\n",
    "classifier_mutual_info_classif: SelectKBest = SelectKBest(score_func=mutual_info_classif_with_random_state, k='all')\n",
    "classifier_mutual_info_regression: SelectKBest = SelectKBest(score_func=mutual_info_regression_with_random_state, k='all')\n",
    "classifier_f_classif: SelectKBest = SelectKBest(score_func=f_classif, k='all')\n",
    "classifier_f_regression: SelectKBest = SelectKBest(score_func=f_regression, k='all')"
   ],
   "id": "99638d58bd84024",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preselecting all the features with each classifier to get a feature ranking.",
   "id": "2a1efd3ac68487d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:14:43.774124Z",
     "start_time": "2025-01-25T09:14:43.772190Z"
    }
   },
   "cell_type": "code",
   "source": "FEATURES_TO_SELECT = 5",
   "id": "9715f9685b56b95c",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:15:32.384264Z",
     "start_time": "2025-01-25T09:15:32.311790Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fits all the feature selection algorithms.\n",
    "\n",
    "selector_list = [\n",
    "    (classifier_chi2, \"classifier_chi2\"),\n",
    "    (classifier_mutual_info_classif, \"classifier_mutual_info_classif\"),\n",
    "    (classifier_mutual_info_regression, \"classifier_mutual_info_regression\"),\n",
    "    (classifier_f_classif, \"classifier_f_classif\"),\n",
    "    (classifier_f_regression, \"classifier_f_regression\")\n",
    "]\n",
    "features_selected_by_each_algorithm: dict = dict()\n",
    "for selector_in_list in selector_list:\n",
    "    selector_in_list: tuple[SelectKBest, str]\n",
    "    selector_in_list[0].fit(data_after_scaling, target_variables)\n",
    "      # Rank the features using Chi-Square algorithm\n",
    "    top_features = get_top_k_features(\n",
    "        selector=selector_in_list[0],\n",
    "        feature_names=features.columns,\n",
    "        top_features_to_select=FEATURES_TO_SELECT,\n",
    "        algorithm=selector_in_list[1],\n",
    "    )\n",
    "    features_selected_by_each_algorithm[selector_in_list[1]] = top_features\n"
   ],
   "id": "f0b36a01d9e3141e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:15:32.392011Z",
     "start_time": "2025-01-25T09:15:32.387259Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def weighted_combine_feature_scores(features_selected_by_each_algorithm_in_func: dict[str, pd.DataFrame],\n",
    "                                    weights: list[float],\n",
    "                                    verbose: bool = VERBOSE) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Sums all the features selected by each algorithm, multiplying each feature by the weight corresponding to it's index.\n",
    "    :param features_selected_by_each_algorithm_in_func:\n",
    "    :param weights:\n",
    "    :param verbose: Printing relevant messages.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if len(features_selected_by_each_algorithm_in_func) != len(weights):\n",
    "        raise ValueError(\"Number of weights does not match number of features selectors\")\n",
    "    combined_scores = pd.DataFrame({\n",
    "        'Feature': [],\n",
    "        'Score': []\n",
    "    })\n",
    "    index = 0\n",
    "    for algorithm_name, features_selected_by_algorithm in features_selected_by_each_algorithm_in_func.items():\n",
    "        if verbose:\n",
    "            print(f'Combining scores for {algorithm_name}, its weight is: {weights[index]}')\n",
    "\n",
    "        features_selected_by_algorithm['Score'] = features_selected_by_algorithm['Score'] * weights[index]\n",
    "        combined_scores = pd.merge(combined_scores,\n",
    "                               features_selected_by_algorithm,\n",
    "                               on='Feature', how='outer', suffixes=('_df1', '_df2'))\n",
    "\n",
    "        # Sum the scores where both exist, fill NaN with 0 for features that only exist in one of the dataframes\n",
    "        combined_scores['Score'] = combined_scores['Score_df1'].fillna(0) + combined_scores['Score_df2'].fillna(0)\n",
    "\n",
    "        # Drop the original score columns if not needed\n",
    "        combined_scores = combined_scores[['Feature', 'Score']]\n",
    "        index += 1\n",
    "    return combined_scores"
   ],
   "id": "bf04ba6ab50bc8cc",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Genetic Algorithm part, will use the cells created above.",
   "id": "41fd9161dd569135"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:15:32.436553Z",
     "start_time": "2025-01-25T09:15:32.434236Z"
    }
   },
   "cell_type": "code",
   "source": "TEST_TRAIN_SPLIT = 0.2",
   "id": "1b0f42e782a6e8cd",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:15:32.481331Z",
     "start_time": "2025-01-25T09:15:32.477782Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fitness_func_as_weights_to_use_from_each_algorithm(ga_instance, solution, solution_idx):\n",
    "    combined_scores = weighted_combine_feature_scores(features_selected_by_each_algorithm_in_func=features_selected_by_each_algorithm,\n",
    "                                                      weights=solution)\n",
    "    combined_sorted_scores = combined_scores.sort_values(by=['Score'], ascending=False)\n",
    "    list_of_sorted_features = combined_sorted_scores.head(FEATURES_TO_SELECT)['Feature'].tolist()\n",
    "    data_with_top_features = data_after_scaling[list_of_sorted_features]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_with_top_features, target_variables, test_size=TEST_TRAIN_SPLIT, random_state=42)\n",
    "    # Train and fit random forest classification model based on feature selected\n",
    "    accuracy = train_and_fit_random_forest(X_train, X_test, y_train, y_test)\n",
    "    if VERBOSE:\n",
    "        print(f'model_accuracy: {accuracy}')\n",
    "    return accuracy"
   ],
   "id": "e9c0e0aa58616476",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:15:35.914623Z",
     "start_time": "2025-01-25T09:15:32.523031Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_generations = 1\n",
    "num_parents_mating = 4\n",
    "\n",
    "sol_per_pop = 12\n",
    "num_genes = len(features_selected_by_each_algorithm) # Use this to control the number of feature selection potential solutions is used.\n",
    "\n",
    "init_range_low = 0\n",
    "init_range_high = 1\n",
    "\n",
    "parent_selection_type = \"sss\" #steady-state selection, meaning it selects the parents with the highest fitness.\n",
    "keep_parents = 1\n",
    "\n",
    "crossover_type = \"single_point\" # Swaps the chromosomes from a certain index onwards between the parents.\n",
    "\n",
    "mutation_type = \"random\"\n",
    "mutation_percent_genes = 20\n",
    "ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                       num_parents_mating=num_parents_mating, # Num of parents to select each generation.\n",
    "                       fitness_func=fitness_func_as_weights_to_use_from_each_algorithm,\n",
    "                       sol_per_pop=sol_per_pop, # Number of solutions per population.\n",
    "                       num_genes=num_genes, # Effectively, the thing that is tweaked for each generation.\n",
    "                       # gene_type=list[float], # The type of gene, meaning of each value inside a chromosome. Supports list.\n",
    "                       init_range_low=init_range_low, # dependent on the gene type, the range of values to be generated.\n",
    "                       init_range_high=init_range_high,\n",
    "                       parent_selection_type=parent_selection_type,\n",
    "                       keep_parents=keep_parents, # Number of parents to keep from current population.\n",
    "                       # keep_elitism = 1, # The number of the solutions with the best fitness that will be kept for next generation.\n",
    "                       crossover_type=crossover_type,\n",
    "                       mutation_type=mutation_type,\n",
    "                       mutation_by_replacement=True, # If the previous gene is replaced or not.\n",
    "                       mutation_percent_genes=mutation_percent_genes, # The probability that each gene will be mutated\n",
    "                       # crossover_type=crossover_func, Can be used to customize a crossover func.\n",
    "                       # mutation_type=mutation_func, Can be used to customize a mutation func.\n",
    "                       )\n",
    "\n",
    "ga_instance.run()\n",
    "print('--------------------------------------------------')\n",
    "print(f'Generation: {num_generations}')\n",
    "solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "print(\"Parameters of the best solution : {solution}\".format(solution=solution))\n",
    "print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n"
   ],
   "id": "e69ec6e51c9fa814",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aviv Metz\\miniconda3\\Lib\\site-packages\\pygad\\pygad.py:744: UserWarning: The percentage of genes to mutate (mutation_percent_genes=20) resulted in selecting (0) genes. The number of genes to mutate is set to 1 (mutation_num_genes=1).\n",
      "If you do not want to mutate any gene, please set mutation_type=None.\n",
      "  warnings.warn(f\"The percentage of genes to mutate (mutation_percent_genes={mutation_percent_genes}) resulted in selecting ({mutation_num_genes}) genes. The number of genes to mutate is set to 1 (mutation_num_genes=1).\\nIf you do not want to mutate any gene, please set mutation_type=None.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Generation: 1\n",
      "Parameters of the best solution : [ 0.19216425 -0.7468849 ]\n",
      "Fitness value of the best solution = 0.8732394366197183\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training the model with the features selected by each algorithm individually to achieve ablation study.",
   "id": "cf23b80a10461249"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-25T09:16:06.584117Z",
     "start_time": "2025-01-25T09:16:06.366689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Checking the performance of the features selected by each model independently.\n",
    "\n",
    "for feature_selection_method_name, features_selected_with_score in features_selected_by_each_algorithm.items():\n",
    "    features_selected_by_algorithm = features_selected_with_score.head(FEATURES_TO_SELECT)['Feature'].tolist()\n",
    "    data_afer_selecting_features = data_after_scaling[features_selected_by_algorithm]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data_afer_selecting_features, target_variables, test_size=TEST_TRAIN_SPLIT, random_state=42)\n",
    "    accuracy = train_and_fit_random_forest(X_train, X_test, y_train, y_test)\n",
    "    print('------------------------------------------------')\n",
    "    print(f'Feature selection method: {feature_selection_method_name}. Accuracy: {accuracy}')"
   ],
   "id": "52e546e8f8eb92b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------\n",
      "Feature selection method: classifier_chi2. Accuracy: 0.8591549295774648\n",
      "------------------------------------------------\n",
      "Feature selection method: classifier_mutual_info_classif. Accuracy: 0.9295774647887324\n"
     ]
    }
   ],
   "execution_count": 26
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
